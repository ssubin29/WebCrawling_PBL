{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup  //라이브러리 dlavhxm\n",
    "// bs4에서 BeautifulSoup를 가져다 쓰겠다\n",
    "res = requests.get('http://v.media.daum.net/v/20170615203441266') \n",
    "//웹페이지 가져오기\n",
    "//웹페이지의 정보가 res라는 변수안에 할당된다!\n",
    "res.content # 변수명만 써줘도 쥬피터 노트북에서는 내용이 출력된다.\n",
    "mydata = soup.find('title')\n",
    "soup = BeautifulSoup(res.content, 'html.parser') #웹페이지 파싱하기\n",
    "print(my.data.get_text()) #필요한 데이터 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests 은 웹페이지를 가져올때 사용하는 라이브러리임. \n",
    "# 웹페이지가 아나라 임의로 페이지를 가져오기 때문에 이번엔 사용안함\n",
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <h1 id = 'title'> [1]크롤링이란? </h1>\n",
    "        <p class='cssstyle'>웹페이지에서 필요한 데이터를 추출하는 것</p>\n",
    "        <p id = 'body' align='center'>파이썬을 중심으로 다양한 웹크롤링 기술 발달</p>\n",
    "    </body>\n",
    "</html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser') \n",
    "data = soup.find('p',attrs={'id':'body'},{'align':'center'})\n",
    "\n",
    "\n",
    "print(data.string) #필요한 데이터 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태그만으로는 선택하기 어려울 때가 있다. \n",
    "# 그럴때 속성까지 딱 집어서 사용하는 4가지 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "data = soup.find('p',class_='cssstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "data = soup.find('p','cssstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "data = soup.find('p',attrs={'id':'body'},{'align':'center'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "data = soup.find('id':'body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 내가 원하는 정보들을 한방에 리스트의 형태로 가져오고 싶다면,\n",
    "# find_all을 쓴다! (for문을 이용해 출력할 수 있다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = soup.find_all('p') \n",
    "for item in data:\n",
    "    print(item.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
