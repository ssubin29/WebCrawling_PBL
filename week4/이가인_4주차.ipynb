{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 실습\n",
    "# 크롤링 강력한 팁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 팁 1 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(왕초보) - 클래스 소개\n",
      "(왕초보) - 블로그 개발 필요한 준비물 준비하기\n",
      "(왕초보) - Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "(왕초보) - 초간단 페이지 만들어보기\n",
      "(왕초보) - 이쁘게 테마 적용해보기\n",
      "(왕초보) - 마크다운 기초 이해하고, 실제 나만의 블로그 페이지 만들기\n",
      "(왕초보) - 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지 꾸며보기\n",
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "titles = soup.find_all('li','course')\n",
    "for title in titles:\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 팁 2 - 추출한 것에서 또 추출하기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 섹션의 리스트만 갖고오고 싶다면?\n",
    "# find()로 추출한 데이터를 다시 find_all()로 원하는 부분을 추출하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(왕초보) - 클래스 소개\n",
      "(왕초보) - 블로그 개발 필요한 준비물 준비하기\n",
      "(왕초보) - Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "(왕초보) - 초간단 페이지 만들어보기\n",
      "(왕초보) - 이쁘게 테마 적용해보기\n",
      "(왕초보) - 마크다운 기초 이해하고, 실제 나만의 블로그 페이지 만들기\n",
      "(왕초보) - 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지 꾸며보기\n",
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "section = soup.find('ul',id='dev_course_list')\n",
    "titles = soup.find_all('li','course')\n",
    "for title in titles:\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 코드에서 잘못된것!?\n",
    "# titles = soup.find_all('li','course') 에서\n",
    "# titles = section.find_all('li','course') 으로 바꿔줘야한다.\n",
    "# soup.find_all()은 soup 내에서 찾는다는 말이고,\n",
    "# section.tind_all()은 section 내에서 찾는다는 말이기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "section = soup.find('ul',id='dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for title in titles:\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 팁 3 - 파이썬 문자열 함수와 함께 쓰기!\n",
    "# 데이터 전처리 (수집한 데이터를 내가 원하는 형태로 가공하는 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. strip() 함수 사용\n",
    "# 2. split() 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 \n",
      "(초급) - 필요한 프로그램 설치 시연 \n",
      "(초급) - 데이터를 엑셀 파일로 만들기 \n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! \n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 \n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 \n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 \n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 \n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "section = soup.find('ul',id='dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for title in titles:\n",
    "    print(title.get_text().split('[')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      " 필요한 프로그램 설치 시연 [5]\n",
      " 데이터를 엑셀 파일로 만들기 [9]\n",
      "     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      " 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      " 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      " 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      " 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "section = soup.find('ul',id='dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for title in titles:\n",
    "    print(title.get_text().split('-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "필요한 프로그램 설치 시연 [5]\n",
      "데이터를 엑셀 파일로 만들기 [9]\n",
      "엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "section = soup.find('ul',id='dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for title in titles:\n",
    "    print(title.get_text().split('-')[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## strip()을 이용했더니 공백없이 깔끔하게 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "+) 만약 추출한 데이터들에 번호를 매기고 싶다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "1 필요한 프로그램 설치 시연 [5]\n",
      "2 데이터를 엑셀 파일로 만들기 [9]\n",
      "3 엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "4 나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "5 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "6 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "7 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "8 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "section = soup.find('ul',id='dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for index, title in enumerate(titles):\n",
    "    print(index, title.get_text().split('-')[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "2 필요한 프로그램 설치 시연 [5]\n",
      "3 데이터를 엑셀 파일로 만들기 [9]\n",
      "4 엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "5 나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "6 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "7 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "8 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "9 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "section = soup.find('ul',id='dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for index, title in enumerate(titles):\n",
    "    print(index+1, title.get_text().split('-')[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "2. 필요한 프로그램 설치 시연 [5]\n",
      "3. 데이터를 엑셀 파일로 만들기 [9]\n",
      "4. 엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "5. 나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "6. 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "7. 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "8. 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "9. 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "section = soup.find('ul',id='dev_course_list')\n",
    "titles = section.find_all('li','course')\n",
    "for index, title in enumerate(titles):\n",
    "    print(str(index+1)+'.', title.get_text().split('-')[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 여러가지로 응용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(왕초보) - 클래스 소개\n",
      "(왕초보) - 블로그 개발 필요한 준비물 준비하기\n",
      "(왕초보) - Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "(왕초보) - 초간단 페이지 만들어보기\n",
      "(왕초보) - 이쁘게 테마 적용해보기\n",
      "(왕초보) - 마크다운 기초 이해하고, 실제 나만의 블로그 페이지 만들기\n",
      "(왕초보) - 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지 꾸며보기\n",
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "items = soup.select('li')\n",
    "for item in items:\n",
    "    print(item.get_text())\n",
    "    \n",
    "#section = soup.find('ul',id='dev_course_list')\n",
    "#titles = section.find_all('li','course')\n",
    "#for index, title in enumerate(titles):\n",
    "#    print(str(index+1)+'.', title.get_text().split('-')[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나만의 엣지있는 블로그 사이트 만들기\n",
      "당신의 커리어에 파이썬을 입히세요! 자신만의 자동 프로그램까지 가져가는 특별한 강의\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "items = soup.select('h3')\n",
    "for item in items:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(왕초보) - 클래스 소개\n",
      "(왕초보) - 블로그 개발 필요한 준비물 준비하기\n",
      "(왕초보) - Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "(왕초보) - 초간단 페이지 만들어보기\n",
      "(왕초보) - 이쁘게 테마 적용해보기\n",
      "(왕초보) - 마크다운 기초 이해하고, 실제 나만의 블로그 페이지 만들기\n",
      "(왕초보) - 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지 꾸며보기\n",
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "items = soup.select('ul li')\n",
    "for item in items:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "면도기\n",
      "크록스 키즈\n",
      "크록스\n",
      "마스크\n",
      "꽃배달\n",
      "카네이션\n",
      "에어팟 프로\n",
      "원피스\n",
      "KF94 마스크\n",
      "어버이날 선물\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://search.shopping.naver.com/best100v2/main.nhn')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "items = soup.select('li>span>a')\n",
    "for item in items:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,120.50\n",
      "5,602.50\n",
      "11,205.00\n",
      "56,025.00\n",
      "112,050.00\n",
      "280,125.00\n",
      "560,250.00\n",
      "0.89\n",
      "4.46\n",
      "8.92\n",
      "22.31\n",
      "44.62\n",
      "89.25\n",
      "446.23\n",
      "1,140.10\n",
      "1,100.90\n",
      "1,131.40\n",
      "1,109.60\n",
      "\n",
      "\t\t\t\t\n",
      "\t\t\t\t\tN/A\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t1,109.00\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "1,120.50원\n",
      "  3.50\n",
      "1,831.10 달러\n",
      " 15.60\n",
      "66.15 달러\n",
      " 0.14\n",
      "0.72 %\n",
      "  0.01\n",
      "10,361.00 달러\n",
      " 335.50\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://finance.naver.com/marketindex/exchangeDetail.nhn?marketindexCd=FX_USDKRW#')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "items = soup.select('tbody>tr td')\n",
    "for item in items:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\r\n",
      "                    [교수자] 2021학년도 1학기 실시간 화상강의 녹화 영상 업로드 안내\r\n",
      "                  \n",
      "\n",
      "2020.08.28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "loing_url=\"https://lms.sungshin.ac.kr/ilos/main/member/login_form.acl\"\n",
    "user = ''\n",
    "password = ''\n",
    "\n",
    "params = dict()\n",
    "params['m_id'] = user\n",
    "params['m_passwd'] = password\n",
    "\n",
    "\n",
    "res = requests.get('https://lms.sungshin.ac.kr/ilos/main/main_form.acl')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "items = soup.select('#contentsIndex > div.index-leftarea02 > div:nth-child(2) > ol > li:nth-child(3)')\n",
    "for item in items:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 335.50\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test_css.html')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "items = soup.select('ul#dev_course_list>li.course.paid')\n",
    "print(item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_course_list>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021.05.07 -> 1,120.50\n",
      "2021.05.06 -> 1,124.00\n",
      "2021.05.04 -> 1,126.00\n",
      "2021.05.03 -> 1,123.00\n",
      "2021.04.30 -> 1,117.50\n",
      "2021.04.29 -> 1,108.50\n",
      "2021.04.28 -> 1,114.00\n",
      "2021.04.27 -> 1,112.00\n",
      "2021.04.26 -> 1,111.00\n",
      "2021.04.23 -> 1,117.50\n",
      "2021.04.22 -> 1,117.50\n",
      "2021.04.21 -> 1,119.00\n",
      "2021.04.20 -> 1,114.50\n",
      "2021.04.19 -> 1,115.00\n",
      "2021.04.16 -> 1,117.00\n",
      "2021.04.15 -> 1,116.50\n",
      "2021.04.14 -> 1,115.50\n",
      "2021.04.13 -> 1,124.50\n",
      "2021.04.12 -> 1,125.00\n",
      "2021.04.09 -> 1,121.00\n",
      "2021.04.08 -> 1,117.50\n",
      "2021.04.07 -> 1,118.50\n",
      "2021.04.06 -> 1,121.50\n",
      "2021.04.05 -> 1,128.50\n",
      "2021.04.02 -> 1,129.00\n",
      "2021.04.01 -> 1,131.50\n",
      "2021.03.31 -> 1,130.00\n",
      "2021.03.30 -> 1,135.00\n",
      "2021.03.29 -> 1,132.50\n",
      "2021.03.26 -> 1,131.50\n",
      "2021.03.25 -> 1,134.50\n",
      "2021.03.24 -> 1,132.50\n",
      "2021.03.23 -> 1,130.50\n",
      "2021.03.22 -> 1,128.00\n",
      "2021.03.19 -> 1,130.00\n",
      "2021.03.18 -> 1,125.00\n",
      "2021.03.17 -> 1,129.50\n",
      "2021.03.16 -> 1,130.50\n",
      "2021.03.15 -> 1,133.50\n",
      "2021.03.12 -> 1,136.50\n",
      "2021.03.11 -> 1,133.00\n",
      "2021.03.10 -> 1,142.00\n",
      "2021.03.09 -> 1,138.50\n",
      "2021.03.08 -> 1,138.00\n",
      "2021.03.05 -> 1,129.00\n",
      "2021.03.04 -> 1,125.00\n",
      "2021.03.03 -> 1,122.50\n",
      "2021.03.02 -> 1,124.50\n",
      "2021.02.26 -> 1,126.00\n",
      "2021.02.25 -> 1,109.00\n",
      "2021.02.24 -> 1,109.00\n",
      "2021.02.23 -> 1,112.00\n",
      "2021.02.22 -> 1,112.00\n",
      "2021.02.19 -> 1,106.50\n",
      "2021.02.18 -> 1,107.00\n",
      "2021.02.17 -> 1,107.50\n",
      "2021.02.16 -> 1,102.00\n",
      "2021.02.15 -> 1,102.50\n",
      "2021.02.10 -> 1,107.00\n",
      "2021.02.09 -> 1,113.50\n",
      "2021.02.08 -> 1,121.00\n",
      "2021.02.05 -> 1,123.50\n",
      "2021.02.04 -> 1,118.50\n",
      "2021.02.03 -> 1,116.00\n",
      "2021.02.02 -> 1,116.00\n",
      "2021.02.01 -> 1,119.50\n",
      "2021.01.29 -> 1,117.50\n",
      "2021.01.28 -> 1,118.00\n",
      "2021.01.27 -> 1,105.00\n",
      "2021.01.26 -> 1,105.50\n",
      "2021.01.25 -> 1,102.50\n",
      "2021.01.22 -> 1,105.00\n",
      "2021.01.21 -> 1,101.00\n",
      "2021.01.20 -> 1,101.50\n",
      "2021.01.19 -> 1,102.50\n",
      "2021.01.18 -> 1,107.00\n",
      "2021.01.15 -> 1,103.50\n",
      "2021.01.14 -> 1,096.00\n",
      "2021.01.13 -> 1,097.00\n",
      "2021.01.12 -> 1,099.00\n",
      "2021.01.11 -> 1,098.00\n",
      "2021.01.08 -> 1,092.00\n",
      "2021.01.07 -> 1,092.00\n",
      "2021.01.06 -> 1,086.50\n",
      "2021.01.05 -> 1,089.00\n",
      "2021.01.04 -> 1,082.50\n",
      "2020.12.31 -> 1,088.00\n",
      "2020.12.30 -> 1,087.50\n",
      "2020.12.29 -> 1,093.50\n",
      "2020.12.28 -> 1,096.50\n",
      "2020.12.24 -> 1,103.50\n",
      "2020.12.23 -> 1,107.50\n",
      "2020.12.22 -> 1,106.50\n",
      "2020.12.21 -> 1,109.00\n",
      "2020.12.18 -> 1,099.50\n",
      "2020.12.17 -> 1,094.00\n",
      "2020.12.16 -> 1,091.00\n",
      "2020.12.15 -> 1,094.50\n",
      "2020.12.14 -> 1,092.50\n",
      "2020.12.11 -> 1,092.00\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for page_num in range(10):\n",
    "    res = requests.get('https://finance.naver.com/marketindex/exchangeDailyQuote.nhn?marketindexCd=FX_USDKRW&page=' + str(page_num + 1))\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    data = soup.select('table.tbl_exchange.today tbody tr')\n",
    "    for item in data:\n",
    "        print (item.get_text().strip().split('\\n')[0],'->',item.get_text().strip().split('\\n')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
